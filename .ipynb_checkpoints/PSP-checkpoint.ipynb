{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0bc8fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "from torch.utils import model_zoo\n",
    "#import deeplab_resnet\n",
    "from torch.autograd import Variable\n",
    "import scipy.misc\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "def initialize_weights(*models):\n",
    "\tfor model in models:\n",
    "\t\tfor module in model.modules():\n",
    "\t\t\tif isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "\t\t\t\tnn.init.kaiming_normal(module.weight)\n",
    "\t\t\t\tif module.bias is not None:\n",
    "\t\t\t\t\tmodule.bias.data.zero_()\n",
    "\t\t\telif isinstance(module, nn.BatchNorm2d):\n",
    "\t\t\t\tmodule.weight.data.fill_(1)\n",
    "\t\t\t\tmodule.bias.data.zero_()\n",
    "\n",
    "class PyramidPool(nn.Module):\n",
    "\n",
    "\tdef __init__(self, in_features, out_features, pool_size):\n",
    "\t\tsuper(PyramidPool,self).__init__()\n",
    "\n",
    "\t\tself.features = nn.Sequential(\n",
    "\t\t\tnn.AdaptiveAvgPool2d(pool_size),\n",
    "\t\t\tnn.Conv2d(in_features, out_features, 1, bias=False),\n",
    "\t\t\tnn.BatchNorm2d(out_features, momentum=.95),\n",
    "\t\t\tnn.ReLU(inplace=True)\n",
    "\t\t)\n",
    "\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tsize=x.size()\n",
    "\t\toutput=F.upsample(self.features(x), size[2:], mode='bilinear')\n",
    "\t\treturn output\n",
    "    \n",
    "class ConvBnRelu(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, ksize, stride, pad, dilation=1,\n",
    "                 groups=1, has_bn=True, norm_layer=nn.BatchNorm2d, bn_eps=1e-5,\n",
    "                 has_relu=True, inplace=True, has_bias=False):\n",
    "        super(ConvBnRelu, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=ksize,\n",
    "                              stride=stride, padding=pad,\n",
    "                              dilation=dilation, groups=groups, bias=has_bias)\n",
    "        self.has_bn = has_bn\n",
    "        if self.has_bn:\n",
    "            self.bn = norm_layer(out_planes, eps=bn_eps)\n",
    "        self.has_relu = has_relu\n",
    "        if self.has_relu:\n",
    "            self.relu = nn.ReLU(inplace=inplace)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.has_bn:\n",
    "            x = self.bn(x)\n",
    "        if self.has_relu:\n",
    "            x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class PSPNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, pretrained = False):\n",
    "        super(PSPNet,self).__init__()\n",
    "        print(\"initializing model\")\n",
    "        #init_net=deeplab_resnet.Res_Deeplab()\n",
    "        #state=torch.load(\"models/MS_DeepLab_resnet_trained_VOC.pth\")\n",
    "        #init_net.load_state_dict(state)\n",
    "        self.resnet = torchvision.models.resnet101(pretrained = pretrained)\n",
    "\n",
    "\n",
    "        self.layer5a = PyramidPool(2048, 512, 1)\n",
    "        self.layer5b = PyramidPool(2048, 512, 2)\n",
    "        self.layer5c = PyramidPool(2048, 512, 3)\n",
    "        self.layer5d = PyramidPool(2048, 512, 6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "        \tnn.Conv2d(4096, 512, 3, padding=1, bias=False),\n",
    "        \tnn.BatchNorm2d(512, momentum=.95),\n",
    "        \tnn.ReLU(inplace=True),\n",
    "        \tnn.Dropout(.1),\n",
    "        \tnn.Conv2d(512, num_classes, 1),\n",
    "        )\n",
    "        self.final2 = nn.Sequential(\n",
    "        \tnn.Conv2d(4, 256, 3, padding=1, bias=False),\n",
    "        \tnn.BatchNorm2d(256, momentum=.95),\n",
    "        \tnn.ReLU(inplace=True),\n",
    "        \tnn.Dropout(.1),\n",
    "            nn.Conv2d(256, 512, 3, padding=1, bias=False),\n",
    "        \tnn.BatchNorm2d(512, momentum=.95),\n",
    "        \tnn.ReLU(inplace=True),\n",
    "        \tnn.Dropout(.1),\n",
    "        \tnn.Conv2d(512, num_classes, 1),\n",
    "        )\n",
    "\n",
    "        initialize_weights(self.layer5a,self.layer5b,self.layer5c,self.layer5d,self.final)\n",
    "        \n",
    "        \n",
    "        pool_scales=[1, 2, 3, 6]\n",
    "        self.conv6 = nn.Sequential(\n",
    "            ConvBnRelu(4096 + len(pool_scales) * 512, 512, 3, 1, 1,\n",
    "                       has_bn=True,\n",
    "                       has_relu=True, has_bias=False, norm_layer=nn.BatchNorm2d),\n",
    "            nn.Dropout2d(0.1, inplace=False),\n",
    "            nn.Conv2d(512, 2, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "        chann = 2048\n",
    "        \n",
    "        self.aux_branch = nn.Sequential(\n",
    "        \tnn.Conv2d(chann//4, chann//2, 3, padding=1, bias=False),\n",
    "        \tnn.BatchNorm2d(chann//2),\n",
    "        \tnn.ReLU(inplace=True),\n",
    "        \tnn.Dropout(.1),\n",
    "        \tnn.Conv2d(chann//2, num_classes, 1),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        count=0\n",
    "        size=x.size()\n",
    "        input_size = (x.size()[2],x.size()[3])\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        #x = self.resnet.maxpool(x)\n",
    "        x = self.resnet.layer1(x)\n",
    "        x_aux= self.resnet.layer2(x)\n",
    "        x= self.resnet.layer3(x_aux)\n",
    "        x = self.resnet.layer4(x)\n",
    "        \n",
    "        x = self.final(torch.cat([x,\n",
    "        \tself.layer5a(x),\n",
    "        \tself.layer5b(x),\n",
    "        \tself.layer5c(x),\n",
    "        \tself.layer5d(x),\n",
    "        ], 1))\n",
    "        \n",
    "            \n",
    "        aux = self.aux_branch(x_aux)\n",
    "        size2 = (aux.size()[2],aux.size()[3])\n",
    "\n",
    "        x =  F.interpolate(x,size =size2,mode='bilinear',align_corners=True )\n",
    "        x = self.final2(torch.cat([x,\n",
    "        \taux\n",
    "        ], 1))\n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "        #x =  F.interpolate(x,size =size2,mode='bilinear',align_corners=True )\n",
    "        #out = torch.cat([x,self.layer5a(x),self.layer5b(x),self.layer5c(x),self.layer5d(x),], 1))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #aux = F.interpolate(aux,size =input_size,mode='bilinear',align_corners=True )\n",
    "        out = F.interpolate(x,size =input_size,mode='bilinear',align_corners=True )\n",
    "        \n",
    "        return out\n",
    "        #x = self.conv6(x)\n",
    "        \n",
    "        #return F.upsample_bilinear(x,size[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9948435a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
