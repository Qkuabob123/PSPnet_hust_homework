{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb16f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from net import Unet_plus_plus\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from Dataset import HorseDataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "from my_augment import Transform_Compose, Train_Transform, Totensor, Test_Transform\n",
    "from utils import calculate_iou, boundary_iou, bce_dice_loss, mask_to_boundary\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "# 此文件为训练文件 参数已经配置好，如果您要自行训练，请在下列root中修改保存图片的路径,并且修改new_model属性为1\n",
    "# 训练过程默认采用CPU 如果您要修改 还请自行修改model等置于GPU运算\n",
    "# 此Unet++ 默认采用了深监督 您可自行去除 并采用全部网络结构用于预测 如果你想加快预测速度可将cut置为true 可以大幅提升预测速率\n",
    "# 如果您仅仅想查看我的模型训练效果，可以将主函数中的main()注释掉，后运行即可，列表中save_num可以控制保存数目\n",
    "# 如果您要新建模型并训练建议把学习率增大至1e-3 或者更换其他lr_schedule 微调模型则相应降低学习率\n",
    "# best_model.pth为训练所得模型参数 Unet_plus_plus.pth为完整模型\n",
    "\n",
    "# 参数列表   以下部分数据 1代表 是 ;0代表 否\n",
    "# ！！！！！！！！！！！！！！！！！！！！！！！！！\n",
    "# 有很多参数您可以默认使用 我把一些最关键的参数放在了参数列表的开头并加以标识\n",
    "# ！！！！！！！！！！！！！！！！！！！！！！！！！\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "# ---------------------------------------------------------------------------\n",
    "# 指向数据集储存位置\n",
    "parser.add_argument('--root', default='D:/Dataset/horse/archive/weizmann_horse_db', help='folder to Dataset')\n",
    "# epoch次数\n",
    "parser.add_argument('--epochs', type=int, default=100, help='number of epochs to train for')\n",
    "# 是否新建模型    1-新建    0-使用历史最佳pth\n",
    "parser.add_argument('--new_model', type=int, help='new model whether or not', default=0)\n",
    "# 是否进行深监督\n",
    "parser.add_argument('--deep_supervision', default=True)\n",
    "# 是否进行减枝    剪枝操作只会对预测过程有用 设为True大幅度提升预测效率\n",
    "parser.add_argument('--cut', default=False)\n",
    "# 学习率\n",
    "parser.add_argument('--lr', type=float, default=1e-4, help='the learning rate')\n",
    "# 最小学习率\n",
    "parser.add_argument('--min_lr', type=float, default=1e-6, help='minimum learning rate')\n",
    "# 保存模型条件    达到此要求会保存一个模型参数 best_biou.pth\n",
    "parser.add_argument('--early_stop_b_iou', type=float, default=0.69, help='the minimal boundary iou')\n",
    "# 保存模型条件    达到此要求会保存一个模型参数 best_iou.pth\n",
    "parser.add_argument('--early_stop_iou', type=float, default=0.90, help='the minimal iou')\n",
    "# 退出训练条件之一 达到此要求代表有机会可以停止训练\n",
    "parser.add_argument('--signal_iou', type=float, default=0.90, help='the signal iou')\n",
    "# ---------------------------------------------------------------------------\n",
    "# 是否打乱数据集\n",
    "parser.add_argument('--shuffle', type=bool, default=False, help='shuffle or not')\n",
    "# 使用多少个子进程导入数据,0代表无子进程，1代表共两个进程，以此类推\n",
    "parser.add_argument('--workers', type=int, help='number of data loading workers', default=0)\n",
    "# 是否使用gpu训练\n",
    "parser.add_argument('--cuda', action='store_true', help='enables cuda')\n",
    "# 网络基本通道数\n",
    "parser.add_argument('--basic_channel', type=int, default=32, help='Batch size')\n",
    "# batch大小\n",
    "parser.add_argument('--batch_size', type=int, default=8, help='Batch size')\n",
    "# 数据集个数\n",
    "parser.add_argument('--total_num', type=int, default=327, help='Number of total images')\n",
    "# 训练集样本个数   85%\n",
    "parser.add_argument('--train_size', type=int, default=278, help='Number of training images')\n",
    "# 测试集样本个数   15%\n",
    "parser.add_argument('--test_size', type=int, default=49, help='Number of test images')\n",
    "# image_size\n",
    "parser.add_argument('--image_size', type=int, default=80, help='the height / width of the input image to network')\n",
    "# 保存预测图片的batch数\n",
    "parser.add_argument('--save_num', type=int, default=49, help='Number of predict images')\n",
    "# SGD参数\n",
    "parser.add_argument('--nesterov', type=bool, default=True, help='the momentum')\n",
    "# 学习率衰减 及 参数控制 采用SGD时才有效\n",
    "parser.add_argument('--momentum', type=float, default=0.9, help='the momentum')\n",
    "# 学习率衰减 及 参数控制\n",
    "parser.add_argument('--weight_decay', default=1e-4, type=float, help='weight decay')\n",
    "# 早停标准\n",
    "parser.add_argument('--early_stopping', default=10, type=int, help='early stopping')\n",
    "# plot_all表示是否显示图片\n",
    "parser.add_argument('--plot_all', type=int, default=0, help='1 == plot all images')\n",
    "# 输出训练结果输出到目标目录\n",
    "parser.add_argument('--outf', default='./logs', help='folder to train_log')\n",
    "# 输出训练预测结果输出到目标目录\n",
    "parser.add_argument('--predict', default='./predict', help='folder to predict')\n",
    "# 设定随机种子\n",
    "parser.add_argument('--manualSeed', type=int, default=11, help='manual seed')\n",
    "\n",
    "opt = parser.parse_args()\n",
    "\n",
    "argsDict = opt.__dict__\n",
    "# 写入参数设置至setting.txt\n",
    "with open('setting.txt', 'w') as f:\n",
    "    f.writelines('------------------ start ------------------' + '\\n')\n",
    "    for eachArg, value in argsDict.items():\n",
    "        f.writelines(eachArg + ' : ' + str(value) + '\\n')\n",
    "    f.writelines('------------------- end -------------------')\n",
    "\n",
    "# 构造输出目录\n",
    "try:\n",
    "    os.makedirs(opt.outf)\n",
    "    os.makedirs(opt.predict)\n",
    "except OSError:\n",
    "    print(\"目录已存在或创建出错\")\n",
    "\n",
    "# 设置随机种子\n",
    "if opt.manualSeed is None:\n",
    "    opt.manualSeed = random.randint(1, 10000)\n",
    "# 载入种子\n",
    "np.random.seed(opt.manualSeed)\n",
    "torch.manual_seed(opt.manualSeed)\n",
    "random.seed(opt.manualSeed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(opt.manualSeed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 载入参数\n",
    "# 训练过程中参数赋值\n",
    "workers = opt.workers\n",
    "new_model = opt.new_model\n",
    "shuffle = opt.shuffle\n",
    "img_path = opt.root\n",
    "save_num = opt.save_num\n",
    "epoch_num = opt.epochs\n",
    "batch_size = opt.batch_size\n",
    "total_num = opt.total_num\n",
    "early_stop_b_iou = opt.early_stop_b_iou\n",
    "early_stop_iou = opt.early_stop_iou\n",
    "signal_iou = opt.signal_iou\n",
    "train_size = opt.train_size\n",
    "test_size = opt.test_size\n",
    "image_size = opt.image_size\n",
    "learning_rate = opt.lr\n",
    "min_learning_rate = opt.min_lr\n",
    "# UNET++网络相关赋值\n",
    "plot_all = opt.plot_all\n",
    "deep_supervision = opt.deep_supervision\n",
    "cut = opt.cut\n",
    "weight_decay = opt.weight_decay\n",
    "early_stopping = opt.early_stopping\n",
    "momentum = opt.momentum\n",
    "nesterov = opt.nesterov\n",
    "# 训练集加测试集不能超过样本总数\n",
    "assert train_size + test_size <= total_num, \"Traing set size + Test set size > Total dataset size\"\n",
    "\n",
    "# 划分训练集and 测试集\n",
    "idx = np.arange(total_num)\n",
    "if shuffle:\n",
    "    np.random.shuffle(idx)\n",
    "    print(\"数据打乱\")\n",
    "else:\n",
    "    print(\"数据未打乱\")\n",
    "training_idx = idx[:train_size]\n",
    "testing_idx = idx[train_size:train_size + test_size]\n",
    "\n",
    "# 图像数据预处理  and 数据增强\n",
    "train_transforms = Transform_Compose([Train_Transform(image_size=image_size), Totensor()])\n",
    "test_transforms = Transform_Compose([Test_Transform(image_size=image_size), Totensor()])\n",
    "\n",
    "# 载入数据\n",
    "print(\"-\" * 30)\n",
    "print(\"载入数据...\")\n",
    "# 分别载入训练数据和测试数据\n",
    "Train_data = HorseDataset(img_path, training_idx, train_transforms)\n",
    "Test_data = HorseDataset(img_path, testing_idx, test_transforms)\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    Train_data,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=workers,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "# 为了能够复现模型结果，将测试集的batch_size设置1,并不打乱数据集\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    Test_data,\n",
    "    batch_size=1,\n",
    "    num_workers=workers,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "\n",
    "# 训练过程\n",
    "def train(model, data_loader, optimizer):\n",
    "    print(\"training...\")\n",
    "    model.train()\n",
    "    # 记录iou,boundary iou,loss\n",
    "    IOU = []\n",
    "    B_IOU = []\n",
    "    LOSS = []\n",
    "    num = 0\n",
    "    # 一整个Epoch训练过程\n",
    "    for image_batch, mask_batch in data_loader:\n",
    "        num += 1\n",
    "        loss = 0\n",
    "        # 判断是否采用深监督  批次输入and输出\n",
    "        if deep_supervision:\n",
    "            outputs = model(image_batch)\n",
    "            for output in outputs:\n",
    "                loss += bce_dice_loss(output, mask_batch)\n",
    "            loss /= len(outputs)\n",
    "            iou = calculate_iou(outputs[-1].squeeze(dim=1), mask_batch)\n",
    "            b_iou = boundary_iou(mask_batch, outputs[-1].squeeze(dim=1))\n",
    "        else:\n",
    "            output = model(image_batch)\n",
    "            loss = bce_dice_loss(output, mask_batch)\n",
    "            iou = calculate_iou(output.squeeze(dim=1), mask_batch)\n",
    "            b_iou = boundary_iou(mask_batch, output.squeeze(dim=1))\n",
    "\n",
    "        print(num, \"iou:\", iou, \"boundary_iou:\", b_iou, \"loss:\", loss.data)\n",
    "        # 记录数据\n",
    "        LOSS.append(loss)\n",
    "        IOU.append(iou)\n",
    "        B_IOU.append(b_iou)\n",
    "\n",
    "        # 参数更新\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    mean_iou = sum(IOU) / len(IOU)\n",
    "    mean_b_iou = sum(B_IOU) / len(B_IOU)\n",
    "    mean_loss = sum(LOSS) / len(LOSS)\n",
    "    print(\"训练集 mean iou\", mean_iou)\n",
    "    print(\"训练集 mean boundary_iou\", mean_b_iou)\n",
    "    print(\"训练集 mean loss\", mean_loss)\n",
    "    return mean_iou, mean_b_iou, mean_loss\n",
    "\n",
    "\n",
    "# test类似于train 只是少了更新过程 不加以赘述\n",
    "def test(model, test_data_loader):\n",
    "    print(\"testing...\")\n",
    "    model.eval()\n",
    "    IOU = []\n",
    "    B_IOU = []\n",
    "    LOSS = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_data, test_mask in test_data_loader:\n",
    "\n",
    "            loss = 0\n",
    "            if deep_supervision:\n",
    "                outputs = model(test_data)\n",
    "                for output in outputs:\n",
    "                    loss += bce_dice_loss(output, test_mask)\n",
    "                loss /= len(outputs)\n",
    "                iou = calculate_iou(outputs[-1].squeeze(dim=1), test_mask)\n",
    "                b_iou = boundary_iou(test_mask, outputs[-1].squeeze(dim=1))\n",
    "\n",
    "            else:\n",
    "                output = model(test_data)\n",
    "                loss += bce_dice_loss(output, test_mask)\n",
    "                iou = calculate_iou(output.squeeze(dim=1), test_mask)\n",
    "                b_iou = boundary_iou(test_mask, output.squeeze(dim=1))\n",
    "\n",
    "            IOU.append(iou)\n",
    "            B_IOU.append(b_iou)\n",
    "            LOSS.append(loss)\n",
    "    mean_iou = sum(IOU) / len(IOU)\n",
    "    mean_b_iou = sum(B_IOU) / len(B_IOU)\n",
    "    mean_loss = sum(LOSS) / len(LOSS)\n",
    "    print(\"测试集 mean iou\", mean_iou)\n",
    "    print(\"测试集 mean boundary_iou\", mean_b_iou)\n",
    "    print(\"测试集 mean loss\", mean_loss)\n",
    "    return mean_iou, mean_b_iou, mean_loss\n",
    "\n",
    "\n",
    "# 保存训练过程中得到数据图像\n",
    "def save_fig(TRAIN_IOU, TRAIN_LOSS, TEST_IOU, TEST_LOSS, LR, EPOCH, TRAIN_B_IOU, TEST_B_IOU):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.title('Mean Iou')\n",
    "    plt.xlabel('EPOCH')\n",
    "    plt.ylabel('Mean Iou')\n",
    "    plt.plot(EPOCH, TRAIN_IOU, label='Train')\n",
    "    plt.plot(EPOCH, TEST_IOU, label='Test')\n",
    "    plt.legend(loc='upper left')\n",
    "    if plot_all == 1:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(r\"./%s/mean_iou.png\" % (opt.outf))\n",
    "    plt.clf()\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.title('Mean Boundary Iou')\n",
    "    plt.xlabel('EPOCH')\n",
    "    plt.ylabel('Mean Boundary Iou')\n",
    "    plt.plot(EPOCH, TRAIN_B_IOU, label='Train')\n",
    "    plt.plot(EPOCH, TEST_B_IOU, label='Test')\n",
    "    plt.legend(loc='upper left')\n",
    "    if plot_all == 1:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(r\"./%s/mean_TEST_boundary_iou.png\" % (opt.outf))\n",
    "    plt.clf()\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.title('Mean Loss')\n",
    "    plt.xlabel('EPOCH')\n",
    "    plt.ylabel('Mean Loss')\n",
    "    plt.plot(EPOCH, TRAIN_LOSS, label='Train')\n",
    "    plt.plot(EPOCH, TEST_LOSS, label='Test')\n",
    "\n",
    "    plt.legend(loc='upper left')\n",
    "    if plot_all == 1:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(r\"./%s/mean_loss.png\" % (opt.outf))\n",
    "    plt.clf()\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.title('learning rate')\n",
    "    plt.xlabel('EPOCH')\n",
    "    plt.ylabel('Learning rate')\n",
    "    plt.plot(EPOCH, LR, label='lr')\n",
    "    plt.legend(loc='upper left')\n",
    "    if plot_all == 1:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(r\"./%s/learning_rate.png\" % (opt.outf))\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# 保存预测结果 包含语义分割预测结果，边界预测结果 和 实际图像分割标签和边界图像 以及 分割差值图像\n",
    "def show_predict(test_data_loader, sign):\n",
    "    print(\"-\" * 34)\n",
    "    print(\"开始预测\")\n",
    "    # 两种载入一种依据模型参数\n",
    "\n",
    "    best_model = Unet_plus_plus(deep_supervision=deep_supervision, cut=cut)  # 默认在CPU上\n",
    "    state_dict = torch.load('best_model.pth')\n",
    "    best_model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    # 直接载入完整模型\n",
    "    # best_model = torch.load('Unet_plus_plus.pth')  #可完整载入模型\n",
    "    # best_model.eval()\n",
    "\n",
    "    if sign == 1:\n",
    "        if cut is True:\n",
    "            print(\"减枝预测结果为:\")\n",
    "        elif cut is not True:\n",
    "            print(\"完整结构预测结果为:\")\n",
    "        test_mean_iou, test_mean_b_iou, test_mean_loss = test(best_model, test_data_loader)\n",
    "    cal = 0\n",
    "    toPIL = transforms.ToPILImage()  # 这个函数可以将张量转为PIL图片，由小数转为0-255之间的像素值\n",
    "    with torch.no_grad():\n",
    "        for test_data, test_mask in test_data_loader:\n",
    "            cal += 1\n",
    "            B, H, W = test_mask.shape\n",
    "            for k in range(B):\n",
    "                pic1 = toPIL(test_data[k])\n",
    "                pic2 = toPIL(test_mask[k])\n",
    "\n",
    "                pic1.save(r\"./%s/%d_%d_ori.png\" % (opt.predict, cal, k))\n",
    "                pic2.save(r\"./%s/%d_%d_mask.png\" % (opt.predict, cal, k))\n",
    "\n",
    "            outputs = best_model(test_data)\n",
    "            # 获得边界\n",
    "            mask_boundary = 255 * mask_to_boundary(test_mask, dilation_ratio=0.02, sign=1)\n",
    "            if deep_supervision is True:\n",
    "                # print(\"采用深监督\")\n",
    "                out_boundary = 255 * mask_to_boundary(outputs[-1].squeeze(dim=1), dilation_ratio=0.02, sign=1)\n",
    "                out = outputs[-1].squeeze(dim=1)\n",
    "            else:\n",
    "                # print(\"无深监督\")\n",
    "                out_boundary = 255 * mask_to_boundary(outputs.squeeze(dim=1), dilation_ratio=0.02, sign=1)\n",
    "                out = outputs.squeeze(dim=1)\n",
    "\n",
    "            Save_out = torch.sigmoid(out).data.cpu().numpy()\n",
    "            Save_out[Save_out > 0.5] = 255\n",
    "            Save_out[Save_out <= 0.5] = 0\n",
    "\n",
    "            test_mask_ = torch.sigmoid(test_mask).data.cpu().numpy()\n",
    "            test_mask_[test_mask_ > 0.5] = 255\n",
    "            test_mask_[test_mask_ <= 0.5] = 0\n",
    "            for j in range(B):\n",
    "                A = Image.fromarray(mask_boundary[j].astype('uint8'))\n",
    "                B = Image.fromarray(out_boundary[j].astype('uint8'))\n",
    "                A.save(r\"./%s/%d_%d_mask_boundary.png\" % (opt.predict, cal, j))\n",
    "                B.save(r\"./%s/%d_%d_predict_boundary.png\" % (opt.predict, cal, j))\n",
    "                Y = test_mask_[j].astype('uint8')\n",
    "                X = Save_out[j].astype('uint8')\n",
    "                sub = np.abs(X - Y)\n",
    "                sub = Image.fromarray(sub)\n",
    "                sub.save(r\"./%s/%d_%d_sub.png\" % (opt.predict, cal, j))\n",
    "                Z = Image.fromarray(X)\n",
    "                Z.save(r\"./%s/%d_%d_predict.png\" % (opt.predict, cal, j))\n",
    "            if (cal == save_num):\n",
    "                print(\"预测结束\")\n",
    "                print(\"-\" * 34)\n",
    "                break\n",
    "\n",
    "\n",
    "def cal_time(data_loader):\n",
    "    cut_model = Unet_plus_plus(deep_supervision=deep_supervision, cut=True)  # 默认在CPU上\n",
    "    cut_state_dict = torch.load('best_model.pth')\n",
    "    cut_model.load_state_dict(cut_state_dict, strict=False)\n",
    "    cut_model.eval()\n",
    "\n",
    "    time_start = time.time()  # 记录开始时间\n",
    "    test(cut_model, data_loader)\n",
    "    time_end = time.time()  # 记录结束时间\n",
    "    time_gap = time_end - time_start  # 计算的时间差为程序的执行时间，单位为秒/s\n",
    "    print(\"剪枝时间间隔为\", time_gap)\n",
    "\n",
    "    not_cut_model = Unet_plus_plus(deep_supervision=deep_supervision, cut=False)  # 默认在CPU上\n",
    "    not_cut_state_dict = torch.load('best_model.pth')\n",
    "    not_cut_model.load_state_dict(not_cut_state_dict, strict=False)\n",
    "    not_cut_model.eval()\n",
    "\n",
    "    time_start = time.time()  # 记录开始时间\n",
    "    test(not_cut_model, data_loader)\n",
    "    time_end = time.time()  # 记录结束时间\n",
    "    time_gap = time_end - time_start  # 计算的时间差为程序的执行时间，单位为秒/s\n",
    "    print(\"不剪枝时间间隔为\", time_gap)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 载入模型 deep_supervision与否来构建模型  后剪枝只在预测过程中使用 对于创建模型不影响，默认为False\n",
    "    print(\"载入Unet++模型...\")\n",
    "    if new_model == 1:\n",
    "        print(\"新建模型\")\n",
    "        model = Unet_plus_plus(input_channel=3, num_classes=1, deep_supervision=deep_supervision, cut=False)  # 默认在cpu上\n",
    "\n",
    "    elif new_model == 0:\n",
    "        print(\"载入历史最佳模型\")\n",
    "        model = Unet_plus_plus(input_channel=3, num_classes=1, deep_supervision=deep_supervision, cut=False)\n",
    "        state_dict = torch.load('best_model.pth')  # 载入参数\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "    else:\n",
    "        model = Unet_plus_plus(input_channel=3, num_classes=1, deep_supervision=deep_supervision, cut=False)\n",
    "\n",
    "    # 定义需要更新的参数\n",
    "    params_to_optimize = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "    # 定义优化器 经过实验Adam效果比较好\n",
    "    print(\"定义优化器...\")\n",
    "    Optimizer = optim.Adam(params_to_optimize, lr=learning_rate, weight_decay=weight_decay)\n",
    "    # Optimizer = optim.SGD(params_to_optimize, lr=learning_rate, momentum=momentum,nesterov=nesterov, weight_decay=weight_decay)\n",
    "\n",
    "    # 定义学习率规划\n",
    "    print(\"定义学习率规划...\")\n",
    "    # 采用模拟余弦退火规划学习率\n",
    "    my_lr_scheduler = lr_scheduler.CosineAnnealingLR(Optimizer, T_max=epoch_num, eta_min=min_learning_rate)\n",
    "\n",
    "    break_sign = 0  # 退出信号\n",
    "    best_iou = early_stop_iou  # 用于记录最佳iou\n",
    "    best_boundary_iou = early_stop_b_iou  # 用于记录最佳boundary iou\n",
    "\n",
    "    # 用于记录\n",
    "    TRAIN_ALL_IOU = []\n",
    "    TRAIN_ALL_B_IOU = []\n",
    "    TRAIN_ALL_LOSS = []\n",
    "    TEST_ALL_LOSS = []\n",
    "    TEST_ALL_IOU = []\n",
    "    TEST_ALL_B_IOU = []\n",
    "    LR = []\n",
    "    EPOCH = []\n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        print(\"_\" * 15, epoch + 1, \"_\" * 15)\n",
    "        print(\"learning_rate\", Optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "\n",
    "        EPOCH.append(epoch + 1)\n",
    "        LR.append(Optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "        # 训练过程\n",
    "        train_mean_iou, train_mean_b_iou, train_mean_loss = train(model, train_data_loader, Optimizer)\n",
    "        # 测试过程\n",
    "        test_mean_iou, test_mean_b_iou, test_mean_loss = test(model, test_data_loader)\n",
    "        # 记录数据\n",
    "        TRAIN_ALL_IOU.append(train_mean_iou)\n",
    "        TRAIN_ALL_B_IOU.append(train_mean_b_iou)\n",
    "        TRAIN_ALL_LOSS.append(train_mean_loss)\n",
    "\n",
    "        TEST_ALL_IOU.append(test_mean_iou)\n",
    "        TEST_ALL_B_IOU.append(test_mean_b_iou)\n",
    "        TEST_ALL_LOSS.append(test_mean_loss)\n",
    "\n",
    "        # 保存最佳iou模型参数\n",
    "        if test_mean_iou > best_iou:\n",
    "            best_iou = test_mean_iou\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            torch.save(model, 'Unet_plus_plus.pth')\n",
    "            break_sign = 0\n",
    "        # 保存最佳boundary iou模型参数\n",
    "        if test_mean_b_iou > best_boundary_iou:\n",
    "            best_boundary_iou = test_mean_b_iou\n",
    "            torch.save(model.state_dict(), 'best_biou.pth')\n",
    "            break_sign = 0\n",
    "\n",
    "        break_sign += 1\n",
    "        print(\"best_iou:\", best_iou, \"best boundary iou:\", best_boundary_iou)\n",
    "        print(\"-\" * 34)\n",
    "\n",
    "        # 停止训练条件\n",
    "        if early_stopping > 0 and break_sign > early_stopping and best_iou > signal_iou:\n",
    "            print(\"达到要求，停止训练\")\n",
    "            break\n",
    "\n",
    "        # 更新学习率\n",
    "        my_lr_scheduler.step()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # 输出记录到文件夹内\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            save_fig(TRAIN_ALL_IOU, TRAIN_ALL_LOSS, TEST_ALL_IOU, TEST_ALL_LOSS, LR, EPOCH, TRAIN_ALL_B_IOU,\n",
    "                     TEST_ALL_B_IOU)\n",
    "            show_predict(test_data_loader, 0)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    save_fig(TRAIN_ALL_IOU, TRAIN_ALL_LOSS, TEST_ALL_IOU, TEST_ALL_LOSS, LR, EPOCH, TRAIN_ALL_B_IOU, TEST_ALL_B_IOU)\n",
    "    show_predict(test_data_loader, 0)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"程序运行开始\")\n",
    "    print(\"-\" * 33)\n",
    "\n",
    "    # 包含训练、测试、预测等过程\n",
    "    main()\n",
    "\n",
    "    # 删除此注释并修改cut可以生成 剪枝或不剪枝 预测\n",
    "    # show_predict(train_data_loader, 1)\n",
    "    # show_predict(test_data_loader, 1)\n",
    "\n",
    "    # 删除此注释可以用于测试时间\n",
    "    # cal_time(test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1526ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# 由于数据进行了归一化\n",
    "# 以0.5作为分界线 大于0.5的为前景 小于0.5的为背景\n",
    "def calculate_iou(predict, mask):\n",
    "    predict = torch.sigmoid(predict).data.cpu().numpy()\n",
    "    mask = torch.sigmoid(mask).data.cpu().numpy()\n",
    "    predict_ = predict > 0.5\n",
    "    mask_ = mask > 0.5\n",
    "    # 进行与或操作 获取交并集\n",
    "    intersection = (predict_ & mask_).sum()\n",
    "    union = (predict_ | mask_).sum()\n",
    "    if union < 1e-5:\n",
    "        return 0\n",
    "    iou = intersection / union\n",
    "\n",
    "    return iou\n",
    "\n",
    "\n",
    "# 通过腐蚀操作获取边界\n",
    "def mask_to_boundary(mask, dilation_ratio=0.02, sign=1):\n",
    "    # 通过sign判断 来讲mask数值置为 0、1\n",
    "    if sign == 1:\n",
    "        mask = torch.sigmoid(mask).data.cpu().numpy()\n",
    "        mask[mask > 0.5] = 1\n",
    "        mask[mask <= 0.5] = 0\n",
    "        mask = mask.astype('uint8')\n",
    "    elif sign == 0:\n",
    "        mask = np.array(mask).astype('uint8')\n",
    "\n",
    "    b, h, w = mask.shape\n",
    "    new_mask = np.zeros([b, h + 2, w + 2])\n",
    "    mask_erode = np.zeros([b, h, w])\n",
    "    img_diag = np.sqrt(h ** 2 + w ** 2)  # 计算图像对角线长度\n",
    "    # 计算腐蚀的程度dilation\n",
    "    dilation = int(round(dilation_ratio * img_diag))\n",
    "    if dilation < 1:\n",
    "        dilation = 1\n",
    "\n",
    "    # 对一个batch中所有进行腐蚀操作\n",
    "    for i in range(b):\n",
    "        new_mask[i] = cv2.copyMakeBorder(mask[i], 1, 1, 1, 1, cv2.BORDER_CONSTANT, value=0)  # 用0填充边框\n",
    "\n",
    "    kernel = np.ones((3, 3), dtype=np.uint8)\n",
    "    for j in range(b):\n",
    "        # 腐蚀操作\n",
    "        new_mask_erode = cv2.erode(new_mask[j], kernel, iterations=dilation)\n",
    "        # 回填\n",
    "        mask_erode[j] = new_mask_erode[1: h + 1, 1: w + 1]\n",
    "\n",
    "    return mask - mask_erode\n",
    "\n",
    "\n",
    "# 获取标签和预测的边界iou\n",
    "def boundary_iou(gt, dt, dilation_ratio=0.02):\n",
    "    dt_boundary = mask_to_boundary(dt, dilation_ratio, sign=1)\n",
    "    gt_boundary = mask_to_boundary(gt, dilation_ratio, sign=0)\n",
    "    B, H, W = dt_boundary.shape\n",
    "    intersection = 0\n",
    "    union = 0\n",
    "    # 计算交并比\n",
    "    for k in range(B):\n",
    "        intersection += ((gt_boundary[k] * dt_boundary[k]) > 0).sum()\n",
    "        union += ((gt_boundary[k] + dt_boundary[k]) > 0).sum()\n",
    "    if union < 1:\n",
    "        return 0\n",
    "    boundary_iou = intersection / union\n",
    "\n",
    "    return boundary_iou\n",
    "\n",
    "\n",
    "def bce_dice_loss(predict_batch, mask_batch):\n",
    "    smooth = 1e-5\n",
    "    # bce loss\n",
    "    squeeze_predict_batch = predict_batch.squeeze(dim=1)\n",
    "    bce = F.binary_cross_entropy_with_logits(squeeze_predict_batch, mask_batch)\n",
    "    # dice loss\n",
    "    torch_predict = torch.sigmoid(squeeze_predict_batch)\n",
    "    num = mask_batch.size(0)\n",
    "    torch_predict = torch_predict.view(num, -1)  # torch展平\n",
    "    mask_batch = mask_batch.view(num, -1)  # torch展平\n",
    "    intersection = (torch_predict * mask_batch)\n",
    "    dice = (2. * intersection.sum(1) + smooth) / (torch_predict.sum(1) + mask_batch.sum(1) + smooth)\n",
    "    dice = 1 - dice.sum() / num\n",
    "    return 0.5 * bce + dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e390de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import re\n",
    "from my_augment import Transform_Compose, Train_Transform, Totensor, Test_Transform\n",
    "from torchvision.transforms import ToPILImage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 此文件用于载入数据\n",
    "\n",
    "# 数据载入\n",
    "root = 'D:/Dataset/horse/archive/weizmann_horse_db'  # 默认设置\n",
    "with open('setting.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "for line in lines:\n",
    "    if \"root\" in line:\n",
    "        line = line.rstrip(\"\\n\")  # 去掉末尾\\n\n",
    "        line_split = line.split(' ')\n",
    "        root = line_split[2]\n",
    "\n",
    "\n",
    "class HorseDataset(Dataset):\n",
    "    def __init__(self, root: str, ID, transforms=None):\n",
    "        super(HorseDataset, self).__init__()\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.ID = ID  # idx用于打乱样本集合 获取数据集中部分图片内容\n",
    "        # 获取所有图像的文件名称，排序是为了保证样本图片和标记图片在列表中的位置一一对应\n",
    "        self.imgs = list(np.array(list(sorted(os.listdir(os.path.join(root, \"horse\")))))[ID])\n",
    "        self.masks = list(np.array(list(sorted(os.listdir(os.path.join(root, \"mask\")))))[ID])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 载入图片\n",
    "        img_path = self.root + '/' + 'horse' + '/' + self.imgs[idx]\n",
    "        mask_path = self.root + '/' + 'mask' + '/' + self.masks[idx]\n",
    "\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        mask = Image.open(mask_path)\n",
    "        if self.transforms is not None:\n",
    "            img, mask = self.transforms(img, mask)\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "# 如下为测试时使用\n",
    "# if __name__ == '__main__':\n",
    "# idx = np.arange(327)\n",
    "# np.random.shuffle(idx)\n",
    "# training_idx = idx[:278]\n",
    "# testing_idx = idx[278:]\n",
    "#\n",
    "# train_transforms = Transform_Compose([Train_Transform(image_size=100),Totensor()])\n",
    "# test_transforms = Transform_Compose([Test_Transform(image_size=100),Totensor()])\n",
    "# train_data = HorseDataset(root,training_idx,train_transforms)\n",
    "# test_data =  HorseDataset(root,testing_idx,test_transforms)\n",
    "#\n",
    "# X,mask = train_data[100]\n",
    "# show = ToPILImage()  # 可以把Tensor转成Image，方便可视化\n",
    "# show(X).show()\n",
    "# mask = np.array(mask)\n",
    "# plt.imshow(mask, cmap=\"gray\")\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad129ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root : D:/Dataset/horse/archive/weizmann_horse_db\n",
    "epochs : 100\n",
    "new_model : 0\n",
    "deep_supervision : True\n",
    "cut : False\n",
    "lr : 0.0001\n",
    "min_lr : 1e-06\n",
    "early_stop_b_iou : 0.69\n",
    "early_stop_iou : 0.9\n",
    "signal_iou : 0.9\n",
    "shuffle : False\n",
    "workers : 0\n",
    "cuda : False\n",
    "basic_channel : 32\n",
    "batch_size : 8\n",
    "total_num : 327\n",
    "train_size : 278\n",
    "test_size : 49\n",
    "image_size : 80\n",
    "save_num : 49\n",
    "nesterov : True\n",
    "momentum : 0.9\n",
    "weight_decay : 0.0001\n",
    "early_stopping : 10\n",
    "plot_all : 0\n",
    "outf : ./logs\n",
    "predict : ./predict\n",
    "manualSeed : 11"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
